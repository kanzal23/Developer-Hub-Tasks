{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXt9xwnbbWRu",
        "outputId": "6c59154d-7e24-422d-cbdf-420e610550bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 7911, number of negative: 7911\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4936\n",
            "[LightGBM] [Info] Number of data points in the train set: 15822, number of used features: 45\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "LightGBM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Non-Default       1.00      1.00      1.00      1978\n",
            "     Default       0.93      0.59      0.72        22\n",
            "\n",
            "    accuracy                           0.99      2000\n",
            "   macro avg       0.96      0.80      0.86      2000\n",
            "weighted avg       0.99      0.99      0.99      2000\n",
            "\n",
            "\n",
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Non-Default       0.99      0.57      0.72      1978\n",
            "     Default       0.01      0.59      0.03        22\n",
            "\n",
            "    accuracy                           0.57      2000\n",
            "   macro avg       0.50      0.58      0.38      2000\n",
            "weighted avg       0.98      0.57      0.71      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/loans_full_schema Task 4.csv\")\n",
        "\n",
        "# Drop irrelevant columns\n",
        "cols_to_drop = [\n",
        "    'Unnamed: 0', 'emp_title', 'annual_income_joint', 'verification_income_joint',\n",
        "    'debt_to_income_joint', 'months_since_last_delinq', 'months_since_90d_late'\n",
        "]\n",
        "df.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "# Create binary target\n",
        "default_statuses = ['Charged Off', 'Default', 'Late (31-120 days)', 'Late (16-30 days)']\n",
        "df['default'] = df['loan_status'].apply(lambda x: 1 if x in default_statuses else 0)\n",
        "df.drop(columns=['loan_status'], inplace=True)\n",
        "\n",
        "# Drop columns with >30% missing and fill the rest\n",
        "df.dropna(thresh=0.7 * len(df), axis=1, inplace=True)\n",
        "df.fillna(df.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "df[cat_cols] = df[cat_cols].apply(LabelEncoder().fit_transform)\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['default'])\n",
        "y = df['default']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train LightGBM\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_resampled, y_resampled)\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "\n",
        "# Train SVM\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_resampled, y_resampled)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"LightGBM Performance:\")\n",
        "print(classification_report(y_test, y_pred_lgbm, target_names=[\"Non-Default\", \"Default\"]))\n",
        "\n",
        "print(\"\\nSVM Performance:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=[\"Non-Default\", \"Default\"]))\n"
      ]
    }
  ]
}